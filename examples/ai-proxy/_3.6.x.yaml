name: ai-proxy
config:
  route_type: "llm/v1/chat"
  auth:
    header_name: "Authorization"
    header_value: "Bearer <OPENAI_API_TOKEN>"
  model:
    provider: "openai"
    name: "gpt-4"
    options:
      max_tokens: 512
      temperature: 1.0
