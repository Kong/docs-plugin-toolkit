{
  "entity_checks": [
    {
      "at_least_one_of": [
        "config.allow_patterns",
        "config.deny_patterns"
      ]
    },
    {
      "conditional": {
        "if_field": "config.match_all_roles",
        "then_match": {
          "eq": false
        },
        "if_match": {
          "eq": true
        },
        "then_field": "config.allow_all_conversation_history"
      }
    }
  ],
  "fields": [
    {
      "protocols": {
        "elements": {
          "type": "string",
          "one_of": [
            "grpc",
            "grpcs",
            "http",
            "https"
          ]
        },
        "default": [
          "grpc",
          "grpcs",
          "http",
          "https"
        ],
        "required": true,
        "description": "A set of strings representing HTTP protocols.",
        "type": "set"
      }
    },
    {
      "config": {
        "type": "record",
        "fields": [
          {
            "allow_patterns": {
              "len_max": 10,
              "type": "array",
              "required": false,
              "description": "Array of valid regex patterns, or valid questions from the 'user' role in chat.",
              "elements": {
                "type": "string",
                "len_min": 1,
                "len_max": 500
              }
            }
          },
          {
            "deny_patterns": {
              "len_max": 10,
              "type": "array",
              "required": false,
              "description": "Array of invalid regex patterns, or invalid questions from the 'user' role in chat.",
              "elements": {
                "type": "string",
                "len_min": 1,
                "len_max": 500
              }
            }
          },
          {
            "allow_all_conversation_history": {
              "type": "boolean",
              "required": true,
              "description": "If true, will ignore all previous chat prompts from the conversation history.",
              "default": false
            }
          },
          {
            "max_request_body_size": {
              "type": "integer",
              "default": 8192,
              "description": "max allowed body size allowed to be introspected. 0 means unlimited, but the size of this body will still be limited by Nginx's client_max_body_size.",
              "gt": 0
            }
          },
          {
            "match_all_roles": {
              "type": "boolean",
              "required": true,
              "description": "If true, will match all roles in addition to 'user' role in conversation history.",
              "default": false
            }
          },
          {
            "llm_format": {
              "one_of": [
                "openai",
                "bedrock",
                "gemini",
                "cohere",
                "huggingface"
              ],
              "type": "string",
              "required": false,
              "description": "LLM input and output format and schema to use",
              "default": "openai"
            }
          },
          {
            "genai_category": {
              "one_of": [
                "text/generation",
                "text/embeddings",
                "audio/transcription",
                "audio/speech",
                "image/generation",
                "video/generation",
                "realtime/generation"
              ],
              "type": "string",
              "required": false,
              "description": "Generative AI category of the request",
              "default": "text/generation"
            }
          }
        ],
        "required": true
      }
    }
  ]
}